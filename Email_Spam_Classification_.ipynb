{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Email Spam Classification .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNt/Qsm/xG+ibY5kxvV3cie",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spandanasirasani1/NLTK/blob/main/Email_Spam_Classification_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooDHmfl3BVbG",
        "outputId": "a49dd34c-a9b5-45e1-95d9-f1a5e52edd10"
      },
      "source": [
        "# Email Spam Classification \n",
        "\n",
        "#Importing The Modules\n",
        "import nltk \n",
        "import pandas as pd\n",
        "from nltk.stem.porter import PorterStemmer # For Stemming \n",
        "from nltk.corpus import stopwords \n",
        "print(\"Done\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TisgXeXGE3Y",
        "outputId": "80d2f416-8479-4100-e6bf-63e6d39b4691"
      },
      "source": [
        "#Reading the dataset\n",
        "\n",
        "messages = pd.read_csv('/content/spam_ham_dataset.csv')\n",
        "\n",
        "messages=messages.drop(labels=['label'],axis=1)\n",
        "\n",
        "print(messages)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      waste                                               text  label_num\n",
            "0       605  Subject: enron methanol ; meter # : 988291\\r\\n...          0\n",
            "1      2349  Subject: hpl nom for january 9 , 2001\\r\\n( see...          0\n",
            "2      3624  Subject: neon retreat\\r\\nho ho ho , we ' re ar...          0\n",
            "3      4685  Subject: photoshop , windows , office . cheap ...          1\n",
            "4      2030  Subject: re : indian springs\\r\\nthis deal is t...          0\n",
            "...     ...                                                ...        ...\n",
            "5166   1518  Subject: put the 10 on the ft\\r\\nthe transport...          0\n",
            "5167    404  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...          0\n",
            "5168   2933  Subject: calpine daily gas nomination\\r\\n>\\r\\n...          0\n",
            "5169   1409  Subject: industrial worksheets for august 2000...          0\n",
            "5170   4807  Subject: important online banking alert\\r\\ndea...          1\n",
            "\n",
            "[5171 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNYguBFnGgaX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b672209-e2df-4c28-fa04-254173edbd5e"
      },
      "source": [
        "import re\n",
        "nltk.download('stopwords')\n",
        "ps  = PorterStemmer()\n",
        "corpus = []\n",
        "for i in range(len(messages)):\n",
        "  sent = re.sub('[^a-zA-Z]',' ',messages['text'][i])\n",
        "  sent = sent.lower()\n",
        "  sent = sent.split()\n",
        "  sent  = [ps.stem(word) for word in sent if word not in set(stopwords.words('english'))]\n",
        "  sent = ' '.join(sent)\n",
        "  corpus.append(sent)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZgt1MTnVbSS",
        "outputId": "517b5ad9-c461-4f29-c865-cd75a0396fbb"
      },
      "source": [
        "#Creating The Bag Of Words\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features=2500)\n",
        "x = cv.fit_transform(corpus).toarray()\n",
        "\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5171, 2500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WOfr996XZOC",
        "outputId": "51e3c9e4-5b03-4bb4-ab3e-1075e2ffee55"
      },
      "source": [
        "y = messages['label_num']\n",
        "print(y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       0\n",
            "1       0\n",
            "2       0\n",
            "3       1\n",
            "4       0\n",
            "       ..\n",
            "5166    0\n",
            "5167    0\n",
            "5168    0\n",
            "5169    0\n",
            "5170    1\n",
            "Name: label_num, Length: 5171, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWCBJq8YYHJo"
      },
      "source": [
        "#Splitting Dta Training Data  Training DATA\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.20,random_state = 0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj81DaYrY9ci"
      },
      "source": [
        "# Training The Data\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "spam_detect = MultinomialNB().fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6U6vkvnaR0E"
      },
      "source": [
        "y_pred = spam_detect.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmvdMPVtbrHB",
        "outputId": "1f7f687c-7cfb-4706-d22d-1a24eb9003cd"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[692  40]\n",
            " [ 22 281]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNISS9Fob8NH",
        "outputId": "01f33a73-7e35-44e4-e0ae-298446d8624c"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "a = accuracy_score(y_test,y_pred)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9400966183574879\n"
          ]
        }
      ]
    }
  ]
}